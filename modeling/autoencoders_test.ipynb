{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.2604 - val_loss: 0.2487\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.2385 - val_loss: 0.2259\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 116us/step - loss: 0.2181 - val_loss: 0.2080\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.2032 - val_loss: 0.1957\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1926 - val_loss: 0.1866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x66192d8d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and decode some digits\n",
    "# note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89b9ea025cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# display original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 1: # temp\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
